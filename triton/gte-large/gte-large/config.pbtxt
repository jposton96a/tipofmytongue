name: "gte-large"
platform: "ensemble"
max_batch_size: 0

input [
  {
    name: "INPUT_TEXT"
    data_type: TYPE_STRING
    dims: [ -1 ]
  }
]

output [
  {
    name: "embedding"
    data_type: TYPE_FP32
    dims: [ -1, -1 ]
  }
]

ensemble_scheduling {
  step [
    {
      model_name: "tokenizer"
      model_version: -1
      input_map {
        key: "INPUT_TEXT"
        value: "INPUT_TEXT"
      }
      output_map {
        key: "input_ids"
        value: "input_ids"
      }
      output_map {
        key: "attention_mask"
        value: "attention_mask"
      }
    },
    {
      model_name: "transformer"
      model_version: -1
      input_map {
        key: "input_ids"
        value: "input_ids"
      }
      input_map {
        key: "attention_mask"
        value: "attention_mask"
      }
      output_map {
        key: "token_embeddings"
        value: "token_embeddings"
      }
    },
    {
      model_name: "postprocess"
      model_version: -1
      input_map {
        key: "token_embeddings"
        value: "token_embeddings"
      }
      input_map {
        key: "attention_mask"
        value: "attention_mask"
      }
      output_map {
        key: "embedding"
        value: "embedding"
      }
    }
  ]
}

version_policy: { 
  latest: { num_versions: 1 }
}

response_cache { 
  enable: True 
}