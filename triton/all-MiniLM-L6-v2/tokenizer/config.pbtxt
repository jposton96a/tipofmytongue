name: "tokenizer"
backend: "python"
max_batch_size: 0

parameters: {
  key: "REPOSITORY"
  value: { string_value: "sentence-transformers" }
}
parameters: {
  key: "MODEL_NAME"
  value: { string_value: "all-MiniLM-L6-v2" }
}

input [
  {
    name: "INPUT_TEXT"
    data_type: TYPE_STRING
    dims: [ -1 ]
  }
]

output [
  {
    name: "input_ids"
    data_type: TYPE_INT64
    dims: [ -1, -1 ]
  },
  {
    name: "attention_mask"
    data_type: TYPE_INT64
    dims: [ -1, -1 ]
  }
]

model_warmup [
{
    name : "tokenizer"
    batch_size: 1
    count: 1
    inputs {
      key: "INPUT_TEXT"
      value: {
        data_type: TYPE_STRING
        dims: 1
        input_data_file: "input_text"
      }
    }
}]

instance_group [
  {
    count: 1
    kind: KIND_CPU
  }
]

version_policy: { 
  latest: { num_versions: 1 }
}

response_cache { 
  enable: True 
}